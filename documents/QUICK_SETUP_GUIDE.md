# ğŸš€ QUICK SETUP GUIDE - Income Prediction Pipeline

## ğŸ“‹ **5-MINUTE SETUP CHECKLIST**

### **âœ… STEP 1: VERIFY FILES ARE IN PLACE**

Make sure you have these files in your project directory:
```
your-project/
â”œâ”€â”€ production_pipeline_complete.py          âœ… Main pipeline
â”œâ”€â”€ production_part1_data_cleaning.py        âœ… Part 1: Data cleaning
â”œâ”€â”€ production_part2_model_inference.py      âœ… Part 2: Model inference  
â”œâ”€â”€ production_part3_business_formatting.py  âœ… Part 3: Business formatting
â”œâ”€â”€ production_incremental_predictions.py    âœ… Incremental storage
â”œâ”€â”€ data/production/final_info_clientes.csv  âœ… Your customer data
â””â”€â”€ models/production/
    â”œâ”€â”€ production_model_catboost_all_data.pkl           âœ… Trained model
    â””â”€â”€ production_frequency_mappings_catboost.pkl       âœ… Frequency mappings
```

### **âœ… STEP 2: UPDATE CONFIGURATION (2 MINUTES)**

Open `production_pipeline_complete.py` and update **lines 53-73**:

```python
class ProductionConfig:
    # ğŸ“ UPDATE THIS PATH to your project root
    BASE_PATH = r"C:\Users\david\OneDrive\Documents\augment-projects\caja-de-ahorros"  # â† CHANGE THIS
    
    # ğŸ“‚ INPUT FILES - Update if your data file has different name/location
    INPUT_FILES = {
        "raw_customer_data": os.path.join(BASE_PATH, "data", "production", "final_info_clientes.csv"),
        # â†‘ CHANGE if your customer data file has different name
    }
    
    # ğŸ¤– MODEL FILES - Update if your model files are in different location
    MODEL_FILES = {
        "trained_model": os.path.join(BASE_PATH, "models", "production", "production_model_catboost_all_data.pkl"),
        "frequency_mappings": os.path.join(BASE_PATH, "models", "production", "production_frequency_mappings_catboost.pkl"),
        # â†‘ CHANGE if your model files are in different location
    }
    
    # ğŸ“ OUTPUT FOLDERS - Update if you want different output location
    OUTPUT_FOLDERS = {
        "predictions": os.path.join(BASE_PATH, "model_pred_files"),  # â† Main output folder
        "temp_data": os.path.join(BASE_PATH, "data", "temp"),        # â† Temporary files
    }
```

### **âœ… STEP 3: TEST RUN (1 MINUTE)**

Open command prompt/terminal in your project directory and run:

```bash
# Test the pipeline
python production_pipeline_complete.py
```

**Expected output:**
```
ğŸ¯ COMPLETE END-TO-END PRODUCTION PIPELINE
================================================================================
ğŸ”§ Income Prediction System - XGBoost Model
ğŸ“‹ Pipeline: Raw Data â†’ Features â†’ Predictions â†’ Master Dataset
================================================================================

[2025-09-14 11:30:00] ğŸ” VALIDATING FILE PATHS AND DEPENDENCIES
[2025-09-14 11:30:00] âœ… raw_customer_data: data/production/final_info_clientes.csv
[2025-09-14 11:30:00] âœ… trained_model: models/production/production_model_catboost_all_data.pkl
[2025-09-14 11:30:01] âœ… All file paths validated successfully

[2025-09-14 11:30:01] ğŸš€ PART 1: DATA CLEANING & FEATURE ENGINEERING
[2025-09-14 11:30:05] âœ… Part 1 completed: (31125, 13)

[2025-09-14 11:30:05] ğŸš€ PART 2: MODEL INFERENCE & PREDICTIONS
[2025-09-14 11:30:15] âœ… Part 2 completed: (31125, 15)

[2025-09-14 11:30:15] ğŸš€ PART 3: BUSINESS FORMATTING & INCREMENTAL STORAGE
[2025-09-14 11:30:20] âœ… Part 3 completed: Incremental storage successful

[2025-09-14 11:30:20] ğŸ‰ COMPLETE PIPELINE SUCCESS!
```

### **âœ… STEP 4: VERIFY OUTPUT (30 SECONDS)**

Check that these files were created:
```
model_pred_files/
â”œâ”€â”€ master_predictions.csv          âœ… Main dataset (CSV)
â”œâ”€â”€ master_predictions.json         âœ… Main dataset (JSON)
â””â”€â”€ pipeline_log_20250914.txt       âœ… Execution log
```

### **âœ… STEP 5: CHECK STATUS (30 SECONDS)**

```bash
# Check pipeline status
python production_pipeline_complete.py status
```

**Expected output:**
```
ğŸ“Š PIPELINE STATUS CHECK
==================================================
âœ… Master dataset exists: 31,125 predictions
ğŸ†” Unique customers: 31,125
ğŸ“… Date range: 2025-09-14 11:30:20 to 2025-09-14 11:30:20
ğŸ’¾ File size: 2.5 MB
```

---

## ğŸ”§ **TROUBLESHOOTING COMMON ISSUES**

### **âŒ "File not found" Error**
```
âŒ raw_customer_data: data/production/final_info_clientes.csv (NOT FOUND)
```
**Solution:** Update the file path in `ProductionConfig.INPUT_FILES`

### **âŒ "Cannot import" Error**
```
âŒ Part 1 failed: Cannot import production_part1_data_cleaning.py
```
**Solution:** Make sure all pipeline files are in the same directory

### **âŒ "Model loading failed" Error**
```
âŒ Part 2 failed: Model loading failed
```
**Solution:** 
1. Check model file exists
2. Verify XGBoost is installed: `pip install xgboost`
3. Update model path in `ProductionConfig.MODEL_FILES`

### **âŒ Permission Error**
```
âŒ Error saving files: Permission denied
```
**Solution:** 
1. Run as administrator (Windows) or with sudo (Linux/Mac)
2. Change output folder to a location you have write access

---

## ğŸ¯ **DAILY USAGE**

### **Regular Production Run:**
```bash
# Run daily predictions
python production_pipeline_complete.py
```

### **Check Current Status:**
```bash
# Check master dataset status
python production_pipeline_complete.py status
```

### **Programmatic Usage:**
```python
from production_pipeline_complete import run_complete_pipeline

# Run pipeline
results = run_complete_pipeline()

if results:
    print(f"Processed {results['execution_summary']['customers_processed']} customers")
    print(f"Processing time: {results['execution_summary']['processing_time_seconds']} seconds")
```

---

## ğŸ“Š **UNDERSTANDING THE OUTPUT**

### **master_predictions.csv** - Main business file
| identificador_unico | predicted_income | income_segment | business_priority | prediction_date |
|---------------------|------------------|----------------|-------------------|-----------------|
| CUST_12345 | 1850.50 | MIDDLE_INCOME_GROWTH | HIGH_PRIORITY | 2025-09-14 11:30:20 |

### **master_predictions.json** - Structured data for systems
```json
{
  "dataset_metadata": {
    "total_predictions": 31125,
    "unique_customers": 31125,
    "last_updated": "2025-09-14 11:30:20"
  },
  "business_summary": {
    "income_segments": {"MIDDLE_INCOME_STABLE": 12000, "HIGH_INCOME_STABLE": 8000},
    "business_priorities": {"HIGH_PRIORITY": 15000, "PREMIUM_PRIORITY": 5000}
  }
}
```

---

## ğŸ”„ **INCREMENTAL PROCESSING**

The pipeline automatically handles incremental updates:

- **First run:** Creates master dataset with all predictions
- **Subsequent runs:** Adds new predictions to existing dataset
- **Same customer + same date:** Replaces old prediction with new one
- **Old predictions:** Automatically archived after 90 days (configurable)

---

## ğŸ“ **SUPPORT**

### **Configuration Issues:**
1. Check file paths in `ProductionConfig` class
2. Verify all required files exist
3. Review error logs in `model_pred_files/pipeline_log_YYYYMMDD.txt`

### **Performance Issues:**
1. Adjust `batch_size` in `PROCESSING_CONFIG`
2. Increase `archive_days` if dataset grows too large
3. Monitor disk space in output folders

### **Business Questions:**
1. Review business classifications in master dataset
2. Check income segments and priorities
3. Analyze prediction confidence levels

---

## âœ… **SUCCESS CRITERIA**

Your setup is successful when:
- âœ… Pipeline runs without errors
- âœ… `master_predictions.csv` is created with your data
- âœ… Log file shows "COMPLETE PIPELINE SUCCESS!"
- âœ… Status command shows dataset information
- âœ… Business teams can open CSV file in Excel

**ğŸ‰ You're ready for production!**
